# ğŸº brew-data-engineering

## ğŸ“Œ DescriÃ§Ã£o
O **brew-data-engineering** Ã© um pipeline de engenharia de dados que extrai informaÃ§Ãµes da API [Open Brewery DB](https://www.openbrewerydb.org/), transforma os dados e os armazena em um Data Lake seguindo a arquitetura de medalhÃ£o (Bronze, Prata e Ouro). O objetivo Ã© estruturar os dados de maneira eficiente para anÃ¡lise e consumo posterior.

## ğŸ—ï¸ Arquitetura
O pipeline segue a arquitetura de dados em camadas:
- ğŸŸ¤ **Bronze**: Dados brutos extraÃ­dos da API e armazenados no Data Lake (AWS S3).
- âšª **Prata**: Dados limpos e padronizados.
- ğŸŸ¡ **Ouro**: Dados agregados e enriquecidos para anÃ¡lise.

## ğŸš€ Tecnologias Utilizadas
- ğŸ **Python**: Para desenvolvimento do pipeline de extraÃ§Ã£o e transformaÃ§Ã£o de dados.
- ğŸˆ **Apache Airflow**: Para orquestraÃ§Ã£o do pipeline de dados.
- â˜ï¸ **AWS S3**: Para armazenamento dos dados estruturados.
- ğŸ¼ **Pandas**: Para manipulaÃ§Ã£o e transformaÃ§Ã£o dos dados.
- ğŸŒ **Requests**: Para extraÃ§Ã£o dos dados da API.


## ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o
1. Clone o repositÃ³rio:
   ```sh
   git clone https://github.com/seu-usuario/brew-data-engineering.git
   cd brew-data-engineering
   ```

2. Crie e ative um ambiente virtual:
   ```sh
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate  # Windows
   ```

3. Instale as dependÃªncias:
   ```sh
   pip install -r requirements.txt
   ```

4. Configure suas credenciais da AWS para acesso ao S3.

5. Inicie o Apache Airflow:
   ```sh
   airflow standalone
   ```

## â–¶ï¸ ExecuÃ§Ã£o do Pipeline
1. Acesse a interface web do Airflow (http://localhost:8080) e ative a DAG do pipeline.
2. O pipeline extrairÃ¡ os dados da API, transformarÃ¡ e armazenarÃ¡ no S3.
3. Os dados processados podem ser utilizados para anÃ¡lises e visualizaÃ§Ã£o.

## ğŸ³ Como Usar com Docker
Para rodar o projeto usando Docker, basta executar:
```sh
docker compose up -d
```
Isso iniciarÃ¡ todos os serviÃ§os necessÃ¡rios automaticamente.

Para visualizar os logs em tempo real:
```sh
docker compose logs -f
```

Para parar e remover os contÃªineres:
```sh
docker compose down
```

## ğŸ¤ ContribuiÃ§Ã£o
Sinta-se Ã  vontade para abrir issues e pull requests para melhorias.

